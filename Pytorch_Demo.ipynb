{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shariq29/Pytorch_Demo/blob/main/Pytorch_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Basics: Tensors & Gradients\n",
        "\n",
        "<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAACfCAMAAABX0UX9AAAAxlBMVEX////uTCwlJSUAAAAhISEiIiIXFxcUFBQcHBwRERHR0dHj4+PuSSgNDQ2Dg4NQUFCgoKCtra2amppmZmbw8PDuRiN1dXXtQRr5zMbp6enNzc01NTX5xLv/+vnuRB/4+PhAQEAuLi7Z2dnCwsL8495JSUn1mor1oJH0kYD+9vTtNgCAgIAxMTGQkJCbm5u0tLReXl796+jziHbyfmlhYWH4urD7083wYUTvWTz3sKXwaFDydl/2rKDuUTP2pZfziXnxcFrwZkzh9DwPAAAMHElEQVR4nO2dCXeaTBSGkXUQiLtEMbinSYzVJI1Z2rTN//9T3x1QGGBAQPvF5Nzn9LSJMCyvd+YuM1BBQBAEQRAEQRAEQRAEQRAEQRAEQRAEQRAEQRAEQRAEQTwG5x99BZ+ZcxflK8/GtFG+0gxMlK88G9OsoHxlOQf1UL6yDN5APZSvJJsOVQ/lK8fAVw/lK8Wm4quH8pXB8xooX0kGO9tD+Uqw9RooXykGjHqmOfvoy/lknL+F6lXcx8i26+uLD7qqz0LoNWjX/c1uml2+Pj08pjVEhIjXANv7Ftlku6bZsR+uP+raTh/Wa1TsiHqzbae2Lz/q4k4e1mtU3KhO9+728xsc//hEvca36MZnjKSz2US8RryPBtLagw+5ulNnYGbYniD87Ow6791HXN2pE7W9hHrgeP1NndcPuLiT5zyz5wIXVzewh+m+fZE8ZNhfLevHOlim19jy+6njvj18EfUEQ9WlxZGOle01dtxtzr+KeCCfLqpnxzlUVrx3AP3qjsnEaOdoMKlm0jvWhVEM7VjybSrZXiOFx32mKClbxPHtqNZqToZ7GtSIkoF1tKGKcjT5ourltr2Xm/c96a/E3LssE10arbIF/IzyzZ73ew0OL3bF3VM+kERR1i1A11SiiPCbNu9nNajphAEaKLrX3kc6RfkunjqlbI8Ol/ZV5j6SKM/rHs2z1tjSQRAiTzMaLLsMLVBvVGeZ5L24PBxHvougFFDIa7zc+HL/ytpJEkkr/K3dWFuKKKtZ+rH0oMfX8l5PcY4j3wujXn6v8bKzWDfLfUTlg0i1QWRRHu9zIFsM+fTlu2MCvgI919616vzMGP7i8gnCSlZEq5nvJMYnsD6m6xaI976FraL1/ChJ+YTvliiP8oSAn0K+czvU4b5AGTRU3aykF2A48rVFRZSquc5x+vJdvwddt1gh5SIoX1XcdO/LkU84U0U9X+9Nla83bSwXi+WqGh9E29Wp4f1QXdUb2x/ZNmfNRj/4lJGvN101VtH9c/EYGtFzsWz2Lkzz0r0HT74GpJpd+LdWq60TF7yCT1e7X1JcR7XrEEtTVc0S581IGtcYjSXaeloTIUpUnXUQ6EyCNrLTnfqq7+Qb9lsjAvsTp5WvV4SEZZabohOQofLp5seTb6X6H3YtIjXiG+cqEYN75lpfe2GpsqjIRKZ/Ww57iLql0KjoTPNCdFGRvm/bdHVoA7tD9ijKRFp7oftWvuoPicje/rIqreKny2QQjHydh0INKcHwl264WfL1QZxRbNuEsA148vUdDUJvsLt1zdFViCKlRdiD62DYU+EMUkXVkkBlzf8mqrSNrOu3I4eG7jD2Lr3DU/mGTRBPBdODP1TwxBeaxZ9gAOtsirTzmAXmZ7+k7JLSeQntvMMaaBVLI5qaKIVBNUe+iUjASGoro9duG5PFWBVFvRtsBfnIdKUr6vhsWl2dOYrfxiGioo6aE6NnGNV6jaiSd1qQjyy6GlFvF9PJZNKo0W9jXKCocxf0Xfc+f6uAy8D8nlL2SHEdmvft163tDwHDkSyPQmNKjn0GKEFuQwvpdXUII4ODgHxK05GtxTYw8vpobwxtRKZXThaOt92gdqzqo8bujE2wPy1nTEp5CfpuqYVAs3DgTGnOkW/oyFsL68Fg5EQiwKkUufyk9bVUUXYiFgu3rFi7T0A+0YnXZboaBJpRK/ctjMqnkC7jvRdw+FHOlAj4G6QOZYyPmXtLy3w58oFEyraHwNVKkfy3C4bJ3GhCvqkK9xur2Cw035FTqHwK05kpfejfErfUQOWL1nAMum/u3jt7CwavcjO3QczdeeBH3En5JmB82jba6qvRzYYjE1auhHwwWlrf4+cYy4GkVD5Si5rPnIgqv85FXUd0rmO4JqKUWVBjGQSOwy637OLuydwNfvzMIyFfD+5GkXbhniMrbFdsaKLFRg5x+QwJ+lbCOKDV7vug8lnRes4E+uOcnyNysg4Yl63csctv97C+KwhXuyPYfMcdk69Xh0GcGeoh/9UZy5jLUXXirmOpx32Nd9A5RG3+j9Tzxqy9rvHa+IdPyreELzB36PIQDF1l1+w97npvSuhC5RsOh+12u2dMGt0xhAaiFV6ycQvOI/xNit1O3Ppa/K4FI6blq+4FLrGNJDXD5sjXLCDfRVijLx70+cxudoEPv1gDbsJp/Viva/PRGOJSEI9IZ8zYRG8u6L1NPTbGx+Rr18Bnc04CAdC2x4J8clSrNpgmSanvHCjf9c500kauHAS+4yd3s0RDA0CWvbSI5ksR6wA3HIzecKckFuVF5Zs4ikI4J6lKou7fM0c+CI7SQpED5QtMxyy/aCX0HdzNEtXMh6g0J5/GbuU2HO76EEVHLz0u35jt6sxu0m4ETcrXg6Cv9m/k24RhR84WSXbDp/nM3UzlG3nMfywa02RIRTvs1tW1iOJEd4i5jglY0pxzknaWfDD6rv+NfEG9oLTjDV2v+cYt2UOkUcusLINFbXtsb6yo0YCXZ30jzjGMjM77D60vcJsZ9c59XB4on7AGf+L5Cwjf4m41Jp8BY5/KOUQf5PMtmD/2Of/GdYTylV/T8juQj+t99su3S3Mh4I/nC1zPyzkaiLbNermeNzUN+wrW194WWaAHavHcihP3WZw5Yoh+dP+npHxeUJiSR5zS2PfMTfv2y0cDfdpp6T9xK4lnHeBn1OSCvN4oCHg48kHWkayZbQ//CTzvXvkMi1ZPadCXuEtOzqvIieLJd3039PHkM1RREflVgFOK+965m3PIJ8yJ7PT6qqIn+mWi4vKDiHHvLAyJEoSOHPlolYasuSc+payD3//zyLeCnGvVJZwdE/L1wU3Hqk/DlioGExQ8+bx6H7docEo5L3+pQR75YOyS56KoJ28xWW3uaqKisvc3BNcQemyefMIZLQIuWafe9nOfQ+U7ZsWFX2/NI59XIgcLSU5SJ+c6vHKhuggOWa2BZwiHQ658bTpTpP8IPh82atJuruMQ+Zh6X1nf8SeYbONPduSSb0JTO5575My09Rzoi6remlYnk2pjbtGZo1AwrnyCMVLp3KaznPb702VN14nEzvOyFJIvrDa7h1ab//KXWeWSj47uosoJznjzvMZap2UvS74dw19gireMK+bLB20sOj2u0QWqGhi67M9wHCrf3aFPqZ3vy1sk3UqplLOs6PwZJzE1NFVP1AiGddEisr/Wmejqkj18XVI1bm20Oba2KwkUmUhjf2rSkIgVCyObklpgovzQmbZw8EyRf9lsNvZP/E1JMFsRodftdjk+s91Yj2RLsoizji5xEabQgL/Op13/4bVRx7XdEheht16vYxNPKzhA3rWvgvArXJ124DzvQU/40gmaYquWjep0Ou0XbdOnbfItLczFgasMgomiUq0D2hadETnkCB/FfeA8SiwzmIULZA56PrphFRivT4qDVlgFI5/5ekjfHUIqJn1K42PX9xV2vo/hJPtB7yapyoqaUhM5eZhFQgVXl14HK/LNp4PeTHKmibmf9Dg1rl/Dtc38okkKzNrmw4yPOo602YjTZ8CsrL8qMIQFXreg7AnouoijPqr2/xJaUYFnioRvoeqHud0JJGa3R4zF/m9mFfapopz2x6hXQHOWnp8dGHMSnxz/ZDCpR179wkJL2iTHXrrOclWt1kdEJPGqwOci8kSl/bq/8Dz7GQpulsr2INgbE9WSJF0WiVP8aZST4pp9GrrzvC/+Gzwzj/+6Jb3uVJJFD3Vc9FGUk4Md/iqmnfmmkdm9Xeq1BzF6TUeSLLC/lArJpyLyLoNKx71PE3B2ZTOmd8j8uveQWSO+4OqTMnBZ/Spu5X6Q9AgX5/dvLrtboUDxSxN5ZyS1QLvy53ETJmPXm8erit0xo+p94AWfGJu3TkS/itlxK8+vD38uLy//PLw/V9yogYLCZce9L8nsya7EMc1Ox3XdTsc0E5sKP4H5xbm4tBMipWK/fp13WR2Lx2d3v3Bev+1c4RsQk1xf2p394pn2K768lM/mobNHQNN+T3t6FxGE85923Mcy2kFA84L9NpPZt3f6enCedm/32G33c725/PvWscN4BYJAu/J+P0DDy8vs/Nf93zf7BgDlHn4PNpihlQD/iwkEQRAEQRAEQRAEQRAEQRAEQRAEQRAEQRAEQRAEQU6S/wCIV/TfHmqm6wAAAABJRU5ErkJggg==\" width=\"600\"\n",
        "     height=\"300\">\n",
        "\n",
        "\n",
        "\n",
        "  PyTorch is an open-source machine learning framework that is primarily used for developing and training deep learning models. It was developed by Facebook's AI Research Lab and released in 2016. PyTorch provides a flexible and dynamic approach to building neural networks, making it a popular choice among researchers and developers.\n",
        "\n",
        "The framework is built on a dynamic computational graph concept, which means that the graph is built and modified on-the-fly as the program runs. This allows for more intuitive and flexible model development, as you can use standard Python control flow statements and debug the model easily.\n",
        "\n",
        "PyTorch supports automatic differentiation, which enables efficient computation of gradients for training neural networks using backpropagation. It provides a rich set of tools and libraries for tasks such as data loading, model building, optimization, and evaluation.\n",
        "\n",
        "One of the key advantages of PyTorch is its support for GPU acceleration, allowing you to train models on GPUs to significantly speed up computations. It also has a large and active community, which means there are plenty of resources, tutorials, and pre-trained models available.\n",
        "\n",
        "PyTorch is often compared to TensorFlow, another popular deep learning framework. While TensorFlow focuses more on static computation graphs, PyTorch emphasizes dynamic computation graphs. This fundamental difference in design philosophy gives PyTorch an edge when it comes to flexibility and ease of use.\n",
        "\n",
        "Overall, PyTorch is widely used in the research community and is gaining popularity in industry applications as well. It provides a powerful and user-friendly platform for building and training deep learning models.\n",
        "\n"
      ],
      "metadata": {
        "id": "hR2r2Ng4UyW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "RkPUEaaGU1Wq"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "ir2kHmIoXZEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number/Scalar\n",
        "\n",
        "t1 = torch.tensor(4.)\n",
        "t1\n",
        "\n",
        "# 4. is a shorthand notation for 4.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jX_ZLQMGXbb0",
        "outputId": "18bdee5c-b38e-4889-ef51-48265f05fefa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7o5cRisxXpvE",
        "outputId": "2923228d-5ab5-4a08-fc77-4a902e14c3ce"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Vector\n",
        "t2 = torch.tensor([1., 2, 3, 4])\n",
        "t2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7lAvfClX13E",
        "outputId": "71647727-7baa-4d13-cc40-c079bdc4852d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix\n",
        "t3 = torch.tensor([\n",
        "    [5., 6],\n",
        "    [7,8],\n",
        "    [9,10]\n",
        "])\n",
        "t3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVs4Nw1yYIoF",
        "outputId": "73537686-249a-4e21-8353-24c1efcb0702"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 dimensional array\n",
        "t4 = torch.tensor([\n",
        "    [\n",
        "        [11, 12, 13],\n",
        "        [14, 15, 16]\n",
        "    ],\n",
        "    [\n",
        "        [17,18,19],\n",
        "        [20,21,22]\n",
        "    ]\n",
        "])\n",
        "\n",
        "t4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tl0NM6YYVDE",
        "outputId": "27c9e5bb-1d5a-4adb-abaa-943ab8bad948"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[11, 12, 13],\n",
              "         [14, 15, 16]],\n",
              "\n",
              "        [[17, 18, 19],\n",
              "         [20, 21, 22]]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t1)\n",
        "t1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb36gN4DYnRV",
        "outputId": "0dfb15c6-2abf-4962-f115-7a23ef8182ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(4.)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t2)\n",
        "t2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkYyXzOtY0Z4",
        "outputId": "58e9c51e-c1b8-4be9-cef0-c5758aade35b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 2., 3., 4.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t3)\n",
        "t3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml--q2-8Y5cR",
        "outputId": "b4569269-ab1f-45e2-a8dd-f279ff214831"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5.,  6.],\n",
            "        [ 7.,  8.],\n",
            "        [ 9., 10.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(t4)\n",
        "t4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-F6r8usWZCEU",
        "outputId": "0fae5db6-a070-42ff-f9f8-9f9c40a60fe6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[11, 12, 13],\n",
            "         [14, 15, 16]],\n",
            "\n",
            "        [[17, 18, 19],\n",
            "         [20, 21, 22]]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor operation and gradients"
      ],
      "metadata": {
        "id": "SNjjJolmZQYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensors\n",
        "\n",
        "x = torch.tensor(3.)\n",
        "w = torch.tensor(4. , requires_grad = True)\n",
        "b = torch.tensor(5., requires_grad = True)\n",
        "\n",
        "x, w, b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5ljXxfDZGTr",
        "outputId": "1c56d7a3-e4c7-4f0c-a159-8b25c78d92e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(3.), tensor(4., requires_grad=True), tensor(5., requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Arithemitc operations\n",
        "\n",
        "y = w*x + b\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAjtPvmqZnbr",
        "outputId": "617209f0-6143-4e6b-a63d-99e88edeb57c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17., grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute derivates\n",
        "y.backward()"
      ],
      "metadata": {
        "id": "cd7zwh1WZy9x"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display gradients\n",
        "print(\"dy/dx: \" ,x.grad)\n",
        "print(\"dy/dw: \", w.grad)\n",
        "print(\"dy/db: \", b.grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dEH2Wk1aqul",
        "outputId": "ce81e4bc-1867-467e-bba3-cc4f52e30e7f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dy/dx:  None\n",
            "dy/dw:  tensor(3.)\n",
            "dy/db:  tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hKv5BH5sa7lR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor functions"
      ],
      "metadata": {
        "id": "G_smRE9hba7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor with a fixed value for every elemnt\n",
        "\n",
        "t6 = torch.full((3,2), 42)\n",
        "t6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqPiKgCfbePU",
        "outputId": "d289e69b-01be-44b3-fe7c-247e874c4173"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42],\n",
              "        [42, 42],\n",
              "        [42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatinate two tensors with compatible shapes\n",
        "t7 = torch.cat((t3, t6))\n",
        "t7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKyuNvnsbqdC",
        "outputId": "6f987efb-6b3e-440c-8b7f-fb15e0f14c44"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5.,  6.],\n",
              "        [ 7.,  8.],\n",
              "        [ 9., 10.],\n",
              "        [42., 42.],\n",
              "        [42., 42.],\n",
              "        [42., 42.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the sin of each element\n",
        "t8 = torch.sin(t7)\n",
        "t8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uMWQD4ab9TS",
        "outputId": "56ea3047-ed1f-4684-cf17-58a1a4766062"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.9589, -0.2794],\n",
              "        [ 0.6570,  0.9894],\n",
              "        [ 0.4121, -0.5440],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165],\n",
              "        [-0.9165, -0.9165]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the shape of a tensor\n",
        "\n",
        "t9 = t8.reshape(3,2,2)\n",
        "t9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Kvd7nfcPOQ",
        "outputId": "20cc251c-e703-4cb3-ac28-dcc0f7f5846e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.9589, -0.2794],\n",
              "         [ 0.6570,  0.9894]],\n",
              "\n",
              "        [[ 0.4121, -0.5440],\n",
              "         [-0.9165, -0.9165]],\n",
              "\n",
              "        [[-0.9165, -0.9165],\n",
              "         [-0.9165, -0.9165]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interoperability with Numpy"
      ],
      "metadata": {
        "id": "-rzy3EUvckvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x = np.array([[1,2], [3, 4.]])\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nrn99D_Ocgtk",
        "outputId": "1ce94143-dd04-49db-bfc2-2652d9d6727a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.from_numpy(x)\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W9w-m_dc0yf",
        "outputId": "1aba77b7-1188-4dcd-87bf-fc5a474e3d34"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.dtype, y.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGzPY5Foc5oF",
        "outputId": "3ec6508d-f75a-42d0-db5d-7c1f41f118b0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y.numpy()\n",
        "z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZkn3mFec-Dv",
        "outputId": "743d6720-c0f8-454b-9daf-65c37b3a51d2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZSm1V5bdFe7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression from Scratch using pytorch"
      ],
      "metadata": {
        "id": "Lldq7pw1fKP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "metadata": {
        "id": "SxVmWrmOfN-a"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making training data\n",
        "# Input ---> (temp, rainfall, humidity) ---> yield of apple and oranges crops\n",
        "\n",
        "inputs = np.array([\n",
        "    [73, 67,43],\n",
        "    [91, 88, 64],\n",
        "    [87, 134, 58],\n",
        "    [102, 43, 37],\n",
        "    [69, 96, 70],\n",
        "], dtype = 'float32')"
      ],
      "metadata": {
        "id": "NeqmVPx_qMF_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target (apples, oranges)\n",
        "\n",
        "target = np.array([\n",
        "    [56, 70],\n",
        "    [81, 101],\n",
        "    [119, 113],\n",
        "    [22, 37],\n",
        "    [103, 119]\n",
        "], dtype = 'float32')"
      ],
      "metadata": {
        "id": "IloGhLOTtUps"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert inputs and target to tensors\n",
        "\n",
        "inputs = torch.from_numpy(inputs)\n",
        "target = torch.from_numpy(target)\n",
        "\n",
        "print(inputs)\n",
        "print(target)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJnovyzuts3_",
        "outputId": "b607dd79-3690-4116-8f7a-7f4430ed67f5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 73.,  67.,  43.],\n",
            "        [ 91.,  88.,  64.],\n",
            "        [ 87., 134.,  58.],\n",
            "        [102.,  43.,  37.],\n",
            "        [ 69.,  96.,  70.]])\n",
            "tensor([[ 56.,  70.],\n",
            "        [ 81., 101.],\n",
            "        [119., 113.],\n",
            "        [ 22.,  37.],\n",
            "        [103., 119.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Weights and biases\n",
        "w = torch.randn(2, 3, requires_grad = True)\n",
        "b = torch.randn(2, requires_grad = True)\n",
        "\n",
        "print(w)\n",
        "print(b)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4CnNduSuL-r",
        "outputId": "257e8b70-07bc-4a45-b1d6-5aa74bf954ee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4292, -0.3286, -0.5471],\n",
            "        [-1.1377, -0.2925, -0.1270]], requires_grad=True)\n",
            "tensor([1.5988, 0.9127], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "\n",
        "# Z = X * W + B\n",
        "def model(x):\n",
        "  return x @ w.t() + b\n",
        "\n"
      ],
      "metadata": {
        "id": "SeH79rcOufGA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "preds = model(inputs)\n",
        "print(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rP-JdPguuuA",
        "outputId": "5b95346d-4192-473b-e5d3-f73ff107da7c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -75.2748, -107.1955],\n",
            "        [-101.3905, -136.4832],\n",
            "        [-111.5085, -144.6250],\n",
            "        [ -76.5506, -132.4061],\n",
            "        [ -97.8607, -114.5564]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loss funtion we will use is MSE -> Mean squared error\n",
        "def MSE(y, y_hat):\n",
        "  diff = y - y_hat\n",
        "\n",
        "  return torch.sum(diff*diff)/diff.numel()"
      ],
      "metadata": {
        "id": "soRsVNN2uvii"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# error\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX2wH_1KwFjL",
        "outputId": "5ac58cbd-ff55-46c0-e22a-dccdfbd2f1b2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(39110.4922, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute gradients\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "RlNew9w5waGB"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(w.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juu4vIiaw6B5",
        "outputId": "11670198-883a-4132-c772-4187d0c0ef9d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4292, -0.3286, -0.5471],\n",
            "        [-1.1377, -0.2925, -0.1270]], requires_grad=True)\n",
            "tensor([[-14029.2764, -15850.8428,  -9678.7842],\n",
            "        [-18070.8867, -19399.6504, -12075.5117]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(b)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEgUY2xnw8p8",
        "outputId": "d90457cf-4b95-493e-e38b-35b897018a96"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.5988, 0.9127], requires_grad=True)\n",
            "tensor([-168.7170, -215.0533])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reset grad\n",
        "w.grad.zero_()\n",
        "b.grad.zero_()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ugiyw7qYxAyM",
        "outputId": "67a2f7d8-4f05-452e-b38c-6c2b3b9c8514"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "tensor([0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust params\n",
        "\n",
        "preds = model(inputs)\n",
        "\n",
        "print(preds)\n",
        "\n",
        "\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMOTwzPzxEHa",
        "outputId": "a99dcc77-34db-447c-bddc-cc68583c947b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -75.2748, -107.1955],\n",
            "        [-101.3905, -136.4832],\n",
            "        [-111.5085, -144.6250],\n",
            "        [ -76.5506, -132.4061],\n",
            "        [ -97.8607, -114.5564]], grad_fn=<AddBackward0>)\n",
            "tensor(39110.4922, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zpwhb4ylxTcD",
        "outputId": "212ed558-1041-4f14-894a-f619e79cb538"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-14029.2764, -15850.8428,  -9678.7842],\n",
            "        [-18070.8867, -19399.6504, -12075.5117]])\n",
            "tensor([-168.7170, -215.0533])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adjust weight & reset grad\n",
        "\n",
        "learning_rate = 1e-5\n",
        "\n",
        "with torch.no_grad():\n",
        "  w -= w.grad * 1e-5\n",
        "  b -= b.grad * 1e-5\n",
        "\n",
        "  w.grad.zero_()\n",
        "  b.grad.zero_()"
      ],
      "metadata": {
        "id": "mWkU36MmxWj9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(w)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ8wEMmjyU_y",
        "outputId": "5ac9e9a4-50d5-41d3-cde4-a57a83c20239"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2889, -0.1701, -0.4503],\n",
            "        [-0.9570, -0.0985, -0.0063]], requires_grad=True)\n",
            "tensor([1.6005, 0.9149], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate again\n",
        "\n",
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8Nt5nc2zKM8",
        "outputId": "e6083a52-55da-49d9-f9fd-bf2da577a2a5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(26449.9785, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training for muliple epochs\n",
        "for i in range(400):\n",
        "  preds = model(inputs)\n",
        "  loss = MSE(target, preds)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    w -= w.grad * 1e-5\n",
        "    b -= b.grad * 1e-5\n",
        "\n",
        "    w.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "  print(f\"Epochs({i}/{100}) & Loss {loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eVuwJdxMzYYt",
        "outputId": "a44f811f-cf7f-44c0-fe7e-e9c56c3a7b21"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs(0/100) & Loss 26449.978515625\n",
            "Epochs(1/100) & Loss 17917.29296875\n",
            "Epochs(2/100) & Loss 12166.302734375\n",
            "Epochs(3/100) & Loss 8289.8671875\n",
            "Epochs(4/100) & Loss 5676.6806640625\n",
            "Epochs(5/100) & Loss 3914.788330078125\n",
            "Epochs(6/100) & Loss 2726.58154296875\n",
            "Epochs(7/100) & Loss 1924.986083984375\n",
            "Epochs(8/100) & Loss 1383.9320068359375\n",
            "Epochs(9/100) & Loss 1018.4638671875\n",
            "Epochs(10/100) & Loss 771.33056640625\n",
            "Epochs(11/100) & Loss 603.9520263671875\n",
            "Epochs(12/100) & Loss 490.3294372558594\n",
            "Epochs(13/100) & Loss 412.94207763671875\n",
            "Epochs(14/100) & Loss 359.9828796386719\n",
            "Epochs(15/100) & Loss 323.4953918457031\n",
            "Epochs(16/100) & Loss 298.1177062988281\n",
            "Epochs(17/100) & Loss 280.23614501953125\n",
            "Epochs(18/100) & Loss 267.4156799316406\n",
            "Epochs(19/100) & Loss 258.01495361328125\n",
            "Epochs(20/100) & Loss 250.9281005859375\n",
            "Epochs(21/100) & Loss 245.40963745117188\n",
            "Epochs(22/100) & Loss 240.95693969726562\n",
            "Epochs(23/100) & Loss 237.23123168945312\n",
            "Epochs(24/100) & Loss 234.00439453125\n",
            "Epochs(25/100) & Loss 231.12216186523438\n",
            "Epochs(26/100) & Loss 228.4806365966797\n",
            "Epochs(27/100) & Loss 226.00997924804688\n",
            "Epochs(28/100) & Loss 223.66259765625\n",
            "Epochs(29/100) & Loss 221.40658569335938\n",
            "Epochs(30/100) & Loss 219.2201385498047\n",
            "Epochs(31/100) & Loss 217.0886993408203\n",
            "Epochs(32/100) & Loss 215.0021514892578\n",
            "Epochs(33/100) & Loss 212.9536590576172\n",
            "Epochs(34/100) & Loss 210.9385528564453\n",
            "Epochs(35/100) & Loss 208.95352172851562\n",
            "Epochs(36/100) & Loss 206.9962615966797\n",
            "Epochs(37/100) & Loss 205.06515502929688\n",
            "Epochs(38/100) & Loss 203.1589813232422\n",
            "Epochs(39/100) & Loss 201.27691650390625\n",
            "Epochs(40/100) & Loss 199.41810607910156\n",
            "Epochs(41/100) & Loss 197.5821075439453\n",
            "Epochs(42/100) & Loss 195.76841735839844\n",
            "Epochs(43/100) & Loss 193.97665405273438\n",
            "Epochs(44/100) & Loss 192.20645141601562\n",
            "Epochs(45/100) & Loss 190.45755004882812\n",
            "Epochs(46/100) & Loss 188.7295379638672\n",
            "Epochs(47/100) & Loss 187.02218627929688\n",
            "Epochs(48/100) & Loss 185.33511352539062\n",
            "Epochs(49/100) & Loss 183.66822814941406\n",
            "Epochs(50/100) & Loss 182.0211181640625\n",
            "Epochs(51/100) & Loss 180.39373779296875\n",
            "Epochs(52/100) & Loss 178.78561401367188\n",
            "Epochs(53/100) & Loss 177.19662475585938\n",
            "Epochs(54/100) & Loss 175.62640380859375\n",
            "Epochs(55/100) & Loss 174.07485961914062\n",
            "Epochs(56/100) & Loss 172.54171752929688\n",
            "Epochs(57/100) & Loss 171.02676391601562\n",
            "Epochs(58/100) & Loss 169.5296630859375\n",
            "Epochs(59/100) & Loss 168.05032348632812\n",
            "Epochs(60/100) & Loss 166.5884246826172\n",
            "Epochs(61/100) & Loss 165.14376831054688\n",
            "Epochs(62/100) & Loss 163.71627807617188\n",
            "Epochs(63/100) & Loss 162.30551147460938\n",
            "Epochs(64/100) & Loss 160.91148376464844\n",
            "Epochs(65/100) & Loss 159.53372192382812\n",
            "Epochs(66/100) & Loss 158.17227172851562\n",
            "Epochs(67/100) & Loss 156.82688903808594\n",
            "Epochs(68/100) & Loss 155.49720764160156\n",
            "Epochs(69/100) & Loss 154.1831817626953\n",
            "Epochs(70/100) & Loss 152.88455200195312\n",
            "Epochs(71/100) & Loss 151.6011505126953\n",
            "Epochs(72/100) & Loss 150.3328399658203\n",
            "Epochs(73/100) & Loss 149.079345703125\n",
            "Epochs(74/100) & Loss 147.84048461914062\n",
            "Epochs(75/100) & Loss 146.6161346435547\n",
            "Epochs(76/100) & Loss 145.40606689453125\n",
            "Epochs(77/100) & Loss 144.21011352539062\n",
            "Epochs(78/100) & Loss 143.02810668945312\n",
            "Epochs(79/100) & Loss 141.85992431640625\n",
            "Epochs(80/100) & Loss 140.70533752441406\n",
            "Epochs(81/100) & Loss 139.56410217285156\n",
            "Epochs(82/100) & Loss 138.43617248535156\n",
            "Epochs(83/100) & Loss 137.32135009765625\n",
            "Epochs(84/100) & Loss 136.2194366455078\n",
            "Epochs(85/100) & Loss 135.13034057617188\n",
            "Epochs(86/100) & Loss 134.05380249023438\n",
            "Epochs(87/100) & Loss 132.98977661132812\n",
            "Epochs(88/100) & Loss 131.93800354003906\n",
            "Epochs(89/100) & Loss 130.89833068847656\n",
            "Epochs(90/100) & Loss 129.87081909179688\n",
            "Epochs(91/100) & Loss 128.8550262451172\n",
            "Epochs(92/100) & Loss 127.85093688964844\n",
            "Epochs(93/100) & Loss 126.85845947265625\n",
            "Epochs(94/100) & Loss 125.87730407714844\n",
            "Epochs(95/100) & Loss 124.90743255615234\n",
            "Epochs(96/100) & Loss 123.94877624511719\n",
            "Epochs(97/100) & Loss 123.0011215209961\n",
            "Epochs(98/100) & Loss 122.06424713134766\n",
            "Epochs(99/100) & Loss 121.1380386352539\n",
            "Epochs(100/100) & Loss 120.22251892089844\n",
            "Epochs(101/100) & Loss 119.3173828125\n",
            "Epochs(102/100) & Loss 118.422607421875\n",
            "Epochs(103/100) & Loss 117.5379867553711\n",
            "Epochs(104/100) & Loss 116.6634521484375\n",
            "Epochs(105/100) & Loss 115.79893493652344\n",
            "Epochs(106/100) & Loss 114.9441146850586\n",
            "Epochs(107/100) & Loss 114.09907531738281\n",
            "Epochs(108/100) & Loss 113.26359558105469\n",
            "Epochs(109/100) & Loss 112.43754577636719\n",
            "Epochs(110/100) & Loss 111.62091064453125\n",
            "Epochs(111/100) & Loss 110.81343841552734\n",
            "Epochs(112/100) & Loss 110.01509094238281\n",
            "Epochs(113/100) & Loss 109.22566986083984\n",
            "Epochs(114/100) & Loss 108.44526672363281\n",
            "Epochs(115/100) & Loss 107.673583984375\n",
            "Epochs(116/100) & Loss 106.9105224609375\n",
            "Epochs(117/100) & Loss 106.15608215332031\n",
            "Epochs(118/100) & Loss 105.4100341796875\n",
            "Epochs(119/100) & Loss 104.67240905761719\n",
            "Epochs(120/100) & Loss 103.94294738769531\n",
            "Epochs(121/100) & Loss 103.22172546386719\n",
            "Epochs(122/100) & Loss 102.50843811035156\n",
            "Epochs(123/100) & Loss 101.80318450927734\n",
            "Epochs(124/100) & Loss 101.105712890625\n",
            "Epochs(125/100) & Loss 100.4159927368164\n",
            "Epochs(126/100) & Loss 99.73396301269531\n",
            "Epochs(127/100) & Loss 99.05952453613281\n",
            "Epochs(128/100) & Loss 98.39247131347656\n",
            "Epochs(129/100) & Loss 97.73277282714844\n",
            "Epochs(130/100) & Loss 97.08040618896484\n",
            "Epochs(131/100) & Loss 96.43518829345703\n",
            "Epochs(132/100) & Loss 95.7971420288086\n",
            "Epochs(133/100) & Loss 95.16606903076172\n",
            "Epochs(134/100) & Loss 94.54196166992188\n",
            "Epochs(135/100) & Loss 93.92462921142578\n",
            "Epochs(136/100) & Loss 93.31409454345703\n",
            "Epochs(137/100) & Loss 92.71018981933594\n",
            "Epochs(138/100) & Loss 92.11286926269531\n",
            "Epochs(139/100) & Loss 91.52214050292969\n",
            "Epochs(140/100) & Loss 90.93780517578125\n",
            "Epochs(141/100) & Loss 90.35979461669922\n",
            "Epochs(142/100) & Loss 89.78807067871094\n",
            "Epochs(143/100) & Loss 89.22254943847656\n",
            "Epochs(144/100) & Loss 88.66313171386719\n",
            "Epochs(145/100) & Loss 88.10975646972656\n",
            "Epochs(146/100) & Loss 87.5623779296875\n",
            "Epochs(147/100) & Loss 87.02088928222656\n",
            "Epochs(148/100) & Loss 86.48516845703125\n",
            "Epochs(149/100) & Loss 85.95528411865234\n",
            "Epochs(150/100) & Loss 85.43097686767578\n",
            "Epochs(151/100) & Loss 84.91234588623047\n",
            "Epochs(152/100) & Loss 84.3992919921875\n",
            "Epochs(153/100) & Loss 83.89165496826172\n",
            "Epochs(154/100) & Loss 83.38941955566406\n",
            "Epochs(155/100) & Loss 82.89256286621094\n",
            "Epochs(156/100) & Loss 82.40093231201172\n",
            "Epochs(157/100) & Loss 81.9145736694336\n",
            "Epochs(158/100) & Loss 81.43330383300781\n",
            "Epochs(159/100) & Loss 80.95716094970703\n",
            "Epochs(160/100) & Loss 80.48601531982422\n",
            "Epochs(161/100) & Loss 80.01982879638672\n",
            "Epochs(162/100) & Loss 79.55853271484375\n",
            "Epochs(163/100) & Loss 79.10206604003906\n",
            "Epochs(164/100) & Loss 78.65039825439453\n",
            "Epochs(165/100) & Loss 78.20344543457031\n",
            "Epochs(166/100) & Loss 77.76116943359375\n",
            "Epochs(167/100) & Loss 77.3234634399414\n",
            "Epochs(168/100) & Loss 76.89033508300781\n",
            "Epochs(169/100) & Loss 76.46167755126953\n",
            "Epochs(170/100) & Loss 76.03748321533203\n",
            "Epochs(171/100) & Loss 75.61768341064453\n",
            "Epochs(172/100) & Loss 75.20216369628906\n",
            "Epochs(173/100) & Loss 74.79093933105469\n",
            "Epochs(174/100) & Loss 74.38397979736328\n",
            "Epochs(175/100) & Loss 73.98118591308594\n",
            "Epochs(176/100) & Loss 73.58248138427734\n",
            "Epochs(177/100) & Loss 73.18787384033203\n",
            "Epochs(178/100) & Loss 72.79725646972656\n",
            "Epochs(179/100) & Loss 72.4106674194336\n",
            "Epochs(180/100) & Loss 72.02798461914062\n",
            "Epochs(181/100) & Loss 71.6491470336914\n",
            "Epochs(182/100) & Loss 71.274169921875\n",
            "Epochs(183/100) & Loss 70.90296173095703\n",
            "Epochs(184/100) & Loss 70.53549194335938\n",
            "Epochs(185/100) & Loss 70.17172241210938\n",
            "Epochs(186/100) & Loss 69.81159973144531\n",
            "Epochs(187/100) & Loss 69.45509338378906\n",
            "Epochs(188/100) & Loss 69.10210418701172\n",
            "Epochs(189/100) & Loss 68.75263977050781\n",
            "Epochs(190/100) & Loss 68.40673065185547\n",
            "Epochs(191/100) & Loss 68.06419372558594\n",
            "Epochs(192/100) & Loss 67.72504425048828\n",
            "Epochs(193/100) & Loss 67.38922882080078\n",
            "Epochs(194/100) & Loss 67.0567626953125\n",
            "Epochs(195/100) & Loss 66.72756958007812\n",
            "Epochs(196/100) & Loss 66.40156555175781\n",
            "Epochs(197/100) & Loss 66.07877349853516\n",
            "Epochs(198/100) & Loss 65.75911712646484\n",
            "Epochs(199/100) & Loss 65.44255065917969\n",
            "Epochs(200/100) & Loss 65.1291275024414\n",
            "Epochs(201/100) & Loss 64.81869506835938\n",
            "Epochs(202/100) & Loss 64.51126861572266\n",
            "Epochs(203/100) & Loss 64.20683288574219\n",
            "Epochs(204/100) & Loss 63.9052848815918\n",
            "Epochs(205/100) & Loss 63.6066780090332\n",
            "Epochs(206/100) & Loss 63.31085968017578\n",
            "Epochs(207/100) & Loss 63.017974853515625\n",
            "Epochs(208/100) & Loss 62.727813720703125\n",
            "Epochs(209/100) & Loss 62.44041061401367\n",
            "Epochs(210/100) & Loss 62.15571212768555\n",
            "Epochs(211/100) & Loss 61.87372589111328\n",
            "Epochs(212/100) & Loss 61.594505310058594\n",
            "Epochs(213/100) & Loss 61.317779541015625\n",
            "Epochs(214/100) & Loss 61.043670654296875\n",
            "Epochs(215/100) & Loss 60.77215576171875\n",
            "Epochs(216/100) & Loss 60.503173828125\n",
            "Epochs(217/100) & Loss 60.236671447753906\n",
            "Epochs(218/100) & Loss 59.97265625\n",
            "Epochs(219/100) & Loss 59.71111297607422\n",
            "Epochs(220/100) & Loss 59.451942443847656\n",
            "Epochs(221/100) & Loss 59.1951904296875\n",
            "Epochs(222/100) & Loss 58.94077682495117\n",
            "Epochs(223/100) & Loss 58.68867874145508\n",
            "Epochs(224/100) & Loss 58.43890380859375\n",
            "Epochs(225/100) & Loss 58.191444396972656\n",
            "Epochs(226/100) & Loss 57.94614791870117\n",
            "Epochs(227/100) & Loss 57.703155517578125\n",
            "Epochs(228/100) & Loss 57.46228790283203\n",
            "Epochs(229/100) & Loss 57.22364044189453\n",
            "Epochs(230/100) & Loss 56.987083435058594\n",
            "Epochs(231/100) & Loss 56.75270462036133\n",
            "Epochs(232/100) & Loss 56.52039337158203\n",
            "Epochs(233/100) & Loss 56.29010772705078\n",
            "Epochs(234/100) & Loss 56.06188201904297\n",
            "Epochs(235/100) & Loss 55.8357048034668\n",
            "Epochs(236/100) & Loss 55.61151123046875\n",
            "Epochs(237/100) & Loss 55.389312744140625\n",
            "Epochs(238/100) & Loss 55.16904830932617\n",
            "Epochs(239/100) & Loss 54.9506721496582\n",
            "Epochs(240/100) & Loss 54.7342529296875\n",
            "Epochs(241/100) & Loss 54.51967239379883\n",
            "Epochs(242/100) & Loss 54.30694580078125\n",
            "Epochs(243/100) & Loss 54.096099853515625\n",
            "Epochs(244/100) & Loss 53.88703536987305\n",
            "Epochs(245/100) & Loss 53.679771423339844\n",
            "Epochs(246/100) & Loss 53.47429656982422\n",
            "Epochs(247/100) & Loss 53.270530700683594\n",
            "Epochs(248/100) & Loss 53.068511962890625\n",
            "Epochs(249/100) & Loss 52.86821746826172\n",
            "Epochs(250/100) & Loss 52.66962814331055\n",
            "Epochs(251/100) & Loss 52.472686767578125\n",
            "Epochs(252/100) & Loss 52.27739715576172\n",
            "Epochs(253/100) & Loss 52.083717346191406\n",
            "Epochs(254/100) & Loss 51.891693115234375\n",
            "Epochs(255/100) & Loss 51.701194763183594\n",
            "Epochs(256/100) & Loss 51.512351989746094\n",
            "Epochs(257/100) & Loss 51.32503128051758\n",
            "Epochs(258/100) & Loss 51.1392707824707\n",
            "Epochs(259/100) & Loss 50.95499038696289\n",
            "Epochs(260/100) & Loss 50.7722282409668\n",
            "Epochs(261/100) & Loss 50.590972900390625\n",
            "Epochs(262/100) & Loss 50.411190032958984\n",
            "Epochs(263/100) & Loss 50.23282241821289\n",
            "Epochs(264/100) & Loss 50.055870056152344\n",
            "Epochs(265/100) & Loss 49.88038635253906\n",
            "Epochs(266/100) & Loss 49.70629119873047\n",
            "Epochs(267/100) & Loss 49.5335693359375\n",
            "Epochs(268/100) & Loss 49.36223220825195\n",
            "Epochs(269/100) & Loss 49.19225311279297\n",
            "Epochs(270/100) & Loss 49.023624420166016\n",
            "Epochs(271/100) & Loss 48.85626983642578\n",
            "Epochs(272/100) & Loss 48.690269470214844\n",
            "Epochs(273/100) & Loss 48.52553176879883\n",
            "Epochs(274/100) & Loss 48.36212921142578\n",
            "Epochs(275/100) & Loss 48.19989776611328\n",
            "Epochs(276/100) & Loss 48.03896713256836\n",
            "Epochs(277/100) & Loss 47.8792724609375\n",
            "Epochs(278/100) & Loss 47.720794677734375\n",
            "Epochs(279/100) & Loss 47.56351852416992\n",
            "Epochs(280/100) & Loss 47.407440185546875\n",
            "Epochs(281/100) & Loss 47.25254821777344\n",
            "Epochs(282/100) & Loss 47.09880447387695\n",
            "Epochs(283/100) & Loss 46.94619369506836\n",
            "Epochs(284/100) & Loss 46.79476547241211\n",
            "Epochs(285/100) & Loss 46.644439697265625\n",
            "Epochs(286/100) & Loss 46.49524688720703\n",
            "Epochs(287/100) & Loss 46.34710693359375\n",
            "Epochs(288/100) & Loss 46.200096130371094\n",
            "Epochs(289/100) & Loss 46.05414962768555\n",
            "Epochs(290/100) & Loss 45.909278869628906\n",
            "Epochs(291/100) & Loss 45.765480041503906\n",
            "Epochs(292/100) & Loss 45.622684478759766\n",
            "Epochs(293/100) & Loss 45.48090744018555\n",
            "Epochs(294/100) & Loss 45.34020233154297\n",
            "Epochs(295/100) & Loss 45.200462341308594\n",
            "Epochs(296/100) & Loss 45.06174087524414\n",
            "Epochs(297/100) & Loss 44.923980712890625\n",
            "Epochs(298/100) & Loss 44.78720474243164\n",
            "Epochs(299/100) & Loss 44.65135955810547\n",
            "Epochs(300/100) & Loss 44.51652145385742\n",
            "Epochs(301/100) & Loss 44.38256072998047\n",
            "Epochs(302/100) & Loss 44.249549865722656\n",
            "Epochs(303/100) & Loss 44.11748504638672\n",
            "Epochs(304/100) & Loss 43.98631286621094\n",
            "Epochs(305/100) & Loss 43.85603713989258\n",
            "Epochs(306/100) & Loss 43.72665786743164\n",
            "Epochs(307/100) & Loss 43.5981559753418\n",
            "Epochs(308/100) & Loss 43.47052764892578\n",
            "Epochs(309/100) & Loss 43.34372329711914\n",
            "Epochs(310/100) & Loss 43.217803955078125\n",
            "Epochs(311/100) & Loss 43.092750549316406\n",
            "Epochs(312/100) & Loss 42.96848678588867\n",
            "Epochs(313/100) & Loss 42.84506607055664\n",
            "Epochs(314/100) & Loss 42.72246551513672\n",
            "Epochs(315/100) & Loss 42.60063934326172\n",
            "Epochs(316/100) & Loss 42.47966003417969\n",
            "Epochs(317/100) & Loss 42.35942840576172\n",
            "Epochs(318/100) & Loss 42.23994827270508\n",
            "Epochs(319/100) & Loss 42.12128829956055\n",
            "Epochs(320/100) & Loss 42.00336456298828\n",
            "Epochs(321/100) & Loss 41.886268615722656\n",
            "Epochs(322/100) & Loss 41.769805908203125\n",
            "Epochs(323/100) & Loss 41.654136657714844\n",
            "Epochs(324/100) & Loss 41.53920364379883\n",
            "Epochs(325/100) & Loss 41.42500686645508\n",
            "Epochs(326/100) & Loss 41.31145477294922\n",
            "Epochs(327/100) & Loss 41.19868469238281\n",
            "Epochs(328/100) & Loss 41.08658981323242\n",
            "Epochs(329/100) & Loss 40.97517395019531\n",
            "Epochs(330/100) & Loss 40.86445236206055\n",
            "Epochs(331/100) & Loss 40.754398345947266\n",
            "Epochs(332/100) & Loss 40.64500045776367\n",
            "Epochs(333/100) & Loss 40.53632736206055\n",
            "Epochs(334/100) & Loss 40.428245544433594\n",
            "Epochs(335/100) & Loss 40.320823669433594\n",
            "Epochs(336/100) & Loss 40.21405792236328\n",
            "Epochs(337/100) & Loss 40.107933044433594\n",
            "Epochs(338/100) & Loss 40.0024299621582\n",
            "Epochs(339/100) & Loss 39.897499084472656\n",
            "Epochs(340/100) & Loss 39.793243408203125\n",
            "Epochs(341/100) & Loss 39.689579010009766\n",
            "Epochs(342/100) & Loss 39.58652877807617\n",
            "Epochs(343/100) & Loss 39.48405838012695\n",
            "Epochs(344/100) & Loss 39.38219451904297\n",
            "Epochs(345/100) & Loss 39.28089904785156\n",
            "Epochs(346/100) & Loss 39.180198669433594\n",
            "Epochs(347/100) & Loss 39.080055236816406\n",
            "Epochs(348/100) & Loss 38.9804573059082\n",
            "Epochs(349/100) & Loss 38.881446838378906\n",
            "Epochs(350/100) & Loss 38.78300094604492\n",
            "Epochs(351/100) & Loss 38.68507766723633\n",
            "Epochs(352/100) & Loss 38.58771896362305\n",
            "Epochs(353/100) & Loss 38.490867614746094\n",
            "Epochs(354/100) & Loss 38.394596099853516\n",
            "Epochs(355/100) & Loss 38.29883575439453\n",
            "Epochs(356/100) & Loss 38.20356369018555\n",
            "Epochs(357/100) & Loss 38.10880661010742\n",
            "Epochs(358/100) & Loss 38.01459503173828\n",
            "Epochs(359/100) & Loss 37.920902252197266\n",
            "Epochs(360/100) & Loss 37.8276481628418\n",
            "Epochs(361/100) & Loss 37.734962463378906\n",
            "Epochs(362/100) & Loss 37.64270782470703\n",
            "Epochs(363/100) & Loss 37.55098342895508\n",
            "Epochs(364/100) & Loss 37.45968246459961\n",
            "Epochs(365/100) & Loss 37.36888885498047\n",
            "Epochs(366/100) & Loss 37.27855682373047\n",
            "Epochs(367/100) & Loss 37.188724517822266\n",
            "Epochs(368/100) & Loss 37.099334716796875\n",
            "Epochs(369/100) & Loss 37.01039123535156\n",
            "Epochs(370/100) & Loss 36.921897888183594\n",
            "Epochs(371/100) & Loss 36.83385467529297\n",
            "Epochs(372/100) & Loss 36.74626922607422\n",
            "Epochs(373/100) & Loss 36.65912628173828\n",
            "Epochs(374/100) & Loss 36.57238006591797\n",
            "Epochs(375/100) & Loss 36.48610305786133\n",
            "Epochs(376/100) & Loss 36.40022659301758\n",
            "Epochs(377/100) & Loss 36.314796447753906\n",
            "Epochs(378/100) & Loss 36.22978973388672\n",
            "Epochs(379/100) & Loss 36.145206451416016\n",
            "Epochs(380/100) & Loss 36.060970306396484\n",
            "Epochs(381/100) & Loss 35.977203369140625\n",
            "Epochs(382/100) & Loss 35.8938102722168\n",
            "Epochs(383/100) & Loss 35.81079864501953\n",
            "Epochs(384/100) & Loss 35.72821807861328\n",
            "Epochs(385/100) & Loss 35.64600372314453\n",
            "Epochs(386/100) & Loss 35.56417465209961\n",
            "Epochs(387/100) & Loss 35.48273849487305\n",
            "Epochs(388/100) & Loss 35.40167999267578\n",
            "Epochs(389/100) & Loss 35.32099533081055\n",
            "Epochs(390/100) & Loss 35.2407341003418\n",
            "Epochs(391/100) & Loss 35.16078186035156\n",
            "Epochs(392/100) & Loss 35.081214904785156\n",
            "Epochs(393/100) & Loss 35.00197219848633\n",
            "Epochs(394/100) & Loss 34.92314529418945\n",
            "Epochs(395/100) & Loss 34.84465789794922\n",
            "Epochs(396/100) & Loss 34.766544342041016\n",
            "Epochs(397/100) & Loss 34.68871307373047\n",
            "Epochs(398/100) & Loss 34.61127853393555\n",
            "Epochs(399/100) & Loss 34.5341911315918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model(inputs)\n",
        "loss = MSE(target, preds)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DO_bRU6Qz86y",
        "outputId": "4f3f257a-74bf-470b-853e-74aa8b8867ca"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(34.4574, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lXBDZCOD04ld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "sqrt(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-lDFge00KLx",
        "outputId": "16837aca-3f3e-45b4-ea26-5787f999fbde"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3167310485.py:2: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
            "  sqrt(loss)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.870043672727364"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPUtWQwQ0OdG",
        "outputId": "2cd61f69-fa58-428a-83ec-00a12b1f7b01"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 58.3421,  67.8082],\n",
              "        [ 79.2211,  95.8779],\n",
              "        [123.5967, 123.1313],\n",
              "        [ 25.9815,  40.9119],\n",
              "        [ 94.1830, 110.5019]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nL8eYlYb0P5i",
        "outputId": "fdcc1670-a1a4-40a4-f348-5a7f938ab538"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 56.,  70.],\n",
              "        [ 81., 101.],\n",
              "        [119., 113.],\n",
              "        [ 22.,  37.],\n",
              "        [103., 119.]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sKJPiCB00SEw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fashion MNIST Neural Net example using Pytorch"
      ],
      "metadata": {
        "id": "ad8zpHxw05V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "1SOick-F09s6"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root = 'data',\n",
        "    train= True,\n",
        "    download = True,\n",
        "    transform = ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download = True,\n",
        "    transform = ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SXyjWQa1RcD",
        "outputId": "06d47aec-bb42-40bc-d837-3452e053eb78"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 26.4M/26.4M [00:02<00:00, 11.3MB/s]\n",
            "100%|| 29.5k/29.5k [00:00<00:00, 192kB/s]\n",
            "100%|| 4.42M/4.42M [00:02<00:00, 1.56MB/s]\n",
            "100%|| 5.15k/5.15k [00:00<00:00, 25.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "9wimdMsj1t_n",
        "outputId": "74201f4c-136d-47cd-e36d-95102184ca33"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchvision.datasets.mnist.FashionMNIST"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>torchvision.datasets.mnist.FashionMNIST</b><br/>def __init__(root: Union[str, Path], train: bool=True, transform: Optional[Callable]=None, target_transform: Optional[Callable]=None, download: bool=False) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/torchvision/datasets/mnist.py</a>`Fashion-MNIST &lt;https://github.com/zalandoresearch/fashion-mnist&gt;`_ Dataset.\n",
              "\n",
              "Args:\n",
              "    root (str or ``pathlib.Path``): Root directory of dataset where ``FashionMNIST/raw/train-images-idx3-ubyte``\n",
              "        and  ``FashionMNIST/raw/t10k-images-idx3-ubyte`` exist.\n",
              "    train (bool, optional): If True, creates dataset from ``train-images-idx3-ubyte``,\n",
              "        otherwise from ``t10k-images-idx3-ubyte``.\n",
              "    transform (callable, optional): A function/transform that  takes in a PIL image\n",
              "        and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
              "    target_transform (callable, optional): A function/transform that takes in the\n",
              "        target and transforms it.\n",
              "    download (bool, optional): If True, downloads the dataset from the internet and\n",
              "        puts it in root directory. If dataset is already downloaded, it is not\n",
              "        downloaded again.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 204);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "  print(\"Shape of X [N, C, H, W] \", X.shape)\n",
        "  print(\"Shape of y: \", y.shape, y.dtype)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3Rnb1uN15BX",
        "outputId": "def943fd-dc65-42eb-cb67-e46bab40a3d1"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0X3IHdWa2fcP",
        "outputId": "05ed499b-b0a1-4bd8-86ab-ecac4fb5b8ef"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the NN Model\n",
        "class NeuralNetwork(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "\n",
        "    self.flatten = nn.Flatten()\n",
        "\n",
        "    # Hidden Layers with ReLU activation function\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10) # Output layer\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    logits = self.linear_relu_stack(x)\n",
        "    return logits\n",
        "\n",
        "\n",
        "model= NeuralNetwork().to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFAJGezT3Kdb",
        "outputId": "0ce94d1a-6565-467f-dd49-221c04cb5ed1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy Loss ----> Because it is a multiclass classification problem\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer ---> SGD ---> Stochastic Gradient Descent\n",
        "# lr = Learning Rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
      ],
      "metadata": {
        "id": "Fq-CRg9C48WQ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Training\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    X, y= X.to(device), y.to(device) # related to gpu computation\n",
        "\n",
        "    # Compute prediction error\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred, y)\n",
        "\n",
        "    # BackPropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch %100 ==0 :\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"Loss: {loss} [{current}/{size}]\")"
      ],
      "metadata": {
        "id": "x4-NOviK5dCW"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "  size = len(dataloader.dataset)\n",
        "\n",
        "  num_batches = len(dataloader)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  test_loss, correct = 0, 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X, y in dataloader:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      pred = model(X)\n",
        "\n",
        "      test_loss += loss_fn(pred, y).item()\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "  test_loss /= num_batches # average loss per batch\n",
        "  correct /= size # %age of correct predictions or accuracy\n",
        "\n",
        "  print(f\"Test Error: \\n Accuracy: {100*correct} %, Avg loss {test_loss}\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ew2nGMBN6hvZ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1} \\n --------------------------\")\n",
        "  train(train_dataloader, model, loss_fn, optimizer)\n",
        "  test(test_dataloader, model, loss_fn)\n",
        "\n",
        "print(\"Done\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NyGltnt7wam",
        "outputId": "e61659e5-dec8-49e2-9a31-f2f48e82123c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 \n",
            " --------------------------\n",
            "Loss: 2.305448293685913 [0/60000]\n",
            "Loss: 2.2888269424438477 [6400/60000]\n",
            "Loss: 2.2740893363952637 [12800/60000]\n",
            "Loss: 2.2647652626037598 [19200/60000]\n",
            "Loss: 2.252135753631592 [25600/60000]\n",
            "Loss: 2.2191739082336426 [32000/60000]\n",
            "Loss: 2.2279558181762695 [38400/60000]\n",
            "Loss: 2.196333408355713 [44800/60000]\n",
            "Loss: 2.1869893074035645 [51200/60000]\n",
            "Loss: 2.150482416152954 [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 43.24 %, Avg loss 2.149875982551818\n",
            "\n",
            "Done\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sczjxn9f8_DE"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save model\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved model state to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8DHTQAO8Ifr",
        "outputId": "284b4508-1a7a-4d41-80ba-8564227aceea"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model state to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Prediction\n",
        "\n",
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "\n",
        "\"Trouser\",\n",
        "\n",
        "\"Pullover\",\n",
        "\n",
        "\"Dress\",\n",
        "\n",
        "\"Coat\",\n",
        "\n",
        "\"Sandal\",\n",
        "\n",
        "\"Shirt\",\n",
        "\n",
        "\"Sneaker\",\n",
        "\n",
        "\"Bag\",\n",
        "\n",
        "\"Ankle boot\"\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "model.eval()\n",
        "\n",
        "x, y = test_data[10][0], test_data[10][1]\n",
        "x = x.to(device)\n",
        "# y = y.to(device)\n",
        "with torch.no_grad():\n",
        "  pred = model(x)\n",
        "  predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "\n",
        "  print(f\"Predicted: {predicted} Actual: {actual}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1oNvFeR9B5g",
        "outputId": "5feeba49-4ed8-4761-cf5e-b8b698b790f0"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: Coat Actual: Coat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'x' contains the image data\n",
        "plt.imshow(x.cpu().squeeze())  # Move tensor to CPU if using GPU\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "b0IdzJmy95yG",
        "outputId": "3bfa11eb-1967-41fc-eea9-99471f0348c7"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p7Les0pa-QFX"
      },
      "execution_count": 58,
      "outputs": []
    }
  ]
}